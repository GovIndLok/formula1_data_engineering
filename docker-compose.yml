# =============================================================================
# F1 Data Engineering - Docker Compose Configuration
# =============================================================================
# Services:
#   - postgres: Airflow metadata database
#   - airflow-init: One-time initialization
#   - airflow-webserver: Airflow UI (port 8080)
#   - airflow-scheduler: DAG scheduler
#
# Usage:
#   1. Copy .env.example to .env
#   2. Adjust values in .env as needed
#   3. Run: docker compose up -d
# =============================================================================

x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: Dockerfile.airflow
  environment:
    &airflow-common-env
    # Airflow Core Settings
    AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR:-LocalExecutor}
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@${POSTGRES_HOST:-postgres}:${POSTGRES_PORT:-5432}/${POSTGRES_DB:-airflow}
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:-}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: ${AIRFLOW_DAGS_PAUSED_AT_CREATION:-true}
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES:-false}
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    # F1 Project specific
    FASTF1_CACHE_PATH: ${FASTF1_CACHE_PATH:-/app/data/cache}
    DATA_OUTPUT_PATH: ${DATA_OUTPUT_PATH:-/app/data/processed}
    F1_SEASONS: ${F1_SEASONS:-2024,2025}
    LOG_LEVEL: ${LOG_LEVEL:-INFO}
    PYTHONPATH: /app/src
  volumes:
    - ./dags:/app/dags:ro
    - ./src:/app/src:ro
    - ./data:/app/data
    - ./logs:/app/logs
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy

services:
  # ---------------------------------------------------------------------------
  # PostgreSQL - Airflow Metadata Database
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    container_name: f1_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-airflow}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-airflow}
      POSTGRES_DB: ${POSTGRES_DB:-airflow}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER:-airflow}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - f1-network

  # ---------------------------------------------------------------------------
  # Airflow Initialization (runs once)
  # ---------------------------------------------------------------------------
  airflow-init:
    <<: *airflow-common
    container_name: f1_airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /app/logs /app/dags /app/data/cache /app/data/processed /app/data/raw
        chown -R "${AIRFLOW_UID:-50000}:0" /app/logs /app/data
        airflow db init
        airflow users create \
          --username "${AIRFLOW_ADMIN_USERNAME:-admin}" \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email "${AIRFLOW_ADMIN_EMAIL:-admin@example.com}" \
          --password "${AIRFLOW_ADMIN_PASSWORD:-admin}"
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_ADMIN_USERNAME:-admin}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD:-admin}
    user: "0:0"
    networks:
      - f1-network

  # ---------------------------------------------------------------------------
  # Airflow Webserver (UI)
  # ---------------------------------------------------------------------------
  airflow-webserver:
    <<: *airflow-common
    container_name: f1_airflow_webserver
    command: webserver
    ports:
      - "${AIRFLOW_WEBSERVER_PORT:-8080}:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - f1-network

  # ---------------------------------------------------------------------------
  # Airflow Scheduler
  # ---------------------------------------------------------------------------
  airflow-scheduler:
    <<: *airflow-common
    container_name: f1_airflow_scheduler
    command: scheduler
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob", "--hostname", "$${HOSTNAME}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - f1-network

volumes:
  postgres-data:
    name: f1_postgres_data

networks:
  f1-network:
    name: f1_data_engineering
    driver: bridge
